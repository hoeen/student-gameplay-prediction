{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.reset_option('all')\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# First model (Catboost)\n",
    "CATS = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
    "NUMS = ['page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "        'hover_duration', 'elapsed_time_diff']\n",
    "DIALOGS = ['that', 'this', 'it', 'you','find','found','Found','notebook','Wells','wells','help','need', 'Oh','Ooh','Jo', 'flag', 'can','and','is','the','to']\n",
    "\n",
    "COLUMNS = [\n",
    "    pl.col(\"page\").cast(pl.Float32),\n",
    "    (\n",
    "        (pl.col(\"elapsed_time\") - pl.col(\"elapsed_time\").shift(1))\n",
    "        .fill_null(0)\n",
    "        .clip(0, 1e9)\n",
    "        .over([\"session_id\", \"level\"])\n",
    "        .alias(\"elapsed_time_diff\")\n",
    "    ),\n",
    "    (\n",
    "        (pl.col(\"screen_coor_x\") - pl.col(\"screen_coor_x\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "    (\n",
    "        (pl.col(\"screen_coor_y\") - pl.col(\"screen_coor_y\").shift(1))\n",
    "        .abs()\n",
    "        .over([\"session_id\", \"level\"])\n",
    "    ),\n",
    "    pl.col(\"fqid\").fill_null(\"fqid_None\"),\n",
    "    pl.col(\"text_fqid\").fill_null(\"text_fqid_None\")\n",
    "]\n",
    "\n",
    "name_feature = ['basic', 'undefined', 'close', 'open', 'prev', 'next']\n",
    "event_name_feature = ['cutscene_click', 'person_click', 'navigate_click',\n",
    "       'observation_click', 'notification_click', 'object_click',\n",
    "       'object_hover', 'map_hover', 'map_click', 'checkpoint',\n",
    "       'notebook_click']\n",
    "\n",
    "\n",
    "sub_fqid_lists = {'0-4': ['gramps',\n",
    " 'wells',\n",
    " 'toentry',\n",
    " 'groupconvo',\n",
    " 'tomap',\n",
    " 'tostacks',\n",
    " 'tobasement',\n",
    " 'boss',\n",
    " 'cs',\n",
    " 'teddy',\n",
    " 'tunic.historicalsociety',\n",
    " 'plaque',\n",
    " 'directory',\n",
    " 'tunic',\n",
    " 'tunic.kohlcenter',\n",
    " 'plaque.face.date',\n",
    " 'notebook',\n",
    " 'tunic.hub.slip',\n",
    " 'tocollection',\n",
    " 'tunic.capitol_0',\n",
    " 'photo',\n",
    " 'intro',\n",
    " 'retirement_letter',\n",
    " 'togrampa',\n",
    " 'janitor',\n",
    " 'chap1_finale',\n",
    " 'report',\n",
    " 'outtolunch',\n",
    " 'chap1_finale_c',\n",
    " 'block_0',\n",
    " 'doorblock',\n",
    " 'tocloset',\n",
    " 'block_tomap2',\n",
    " 'block_tocollection',\n",
    " 'block_tomap1'],\n",
    "                  '5-12': ['worker',\n",
    " 'archivist',\n",
    " 'gramps',\n",
    " 'toentry',\n",
    " 'tomap',\n",
    " 'tostacks',\n",
    " 'tobasement',\n",
    " 'boss',\n",
    " 'journals',\n",
    " 'businesscards',\n",
    " 'tunic.historicalsociety',\n",
    " 'tofrontdesk',\n",
    " 'plaque',\n",
    " 'tunic.drycleaner',\n",
    " 'tunic.library',\n",
    " 'trigger_scarf',\n",
    " 'reader',\n",
    " 'directory',\n",
    " 'tunic.capitol_1',\n",
    " 'journals.pic_0.next',\n",
    " 'tunic',\n",
    " 'what_happened',\n",
    " 'tunic.kohlcenter',\n",
    " 'tunic.humanecology',\n",
    " 'logbook',\n",
    " 'businesscards.card_0.next',\n",
    " 'journals.hub.topics',\n",
    " 'logbook.page.bingo',\n",
    " 'journals.pic_1.next',\n",
    " 'reader.paper0.next',\n",
    " 'trigger_coffee',\n",
    " 'wellsbadge',\n",
    " 'journals.pic_2.next',\n",
    " 'tomicrofiche',\n",
    " 'tocloset_dirty',\n",
    " 'businesscards.card_bingo.bingo',\n",
    " 'businesscards.card_1.next',\n",
    " 'tunic.hub.slip',\n",
    " 'journals.pic_2.bingo',\n",
    " 'tocollection',\n",
    " 'chap2_finale_c',\n",
    " 'tunic.capitol_0',\n",
    " 'photo',\n",
    " 'reader.paper1.next',\n",
    " 'businesscards.card_bingo.next',\n",
    " 'reader.paper2.bingo',\n",
    " 'magnify',\n",
    " 'janitor',\n",
    " 'tohallway',\n",
    " 'outtolunch',\n",
    " 'reader.paper2.next',\n",
    " 'door_block_talk',\n",
    " 'block_magnify',\n",
    " 'reader.paper0.prev',\n",
    " 'block',\n",
    " 'block_0',\n",
    " 'door_block_clean',\n",
    " 'reader.paper2.prev',\n",
    " 'reader.paper1.prev',\n",
    " 'block_badge',\n",
    " 'block_badge_2',\n",
    " 'block_1'],\n",
    "                  '13-22': ['worker',\n",
    " 'gramps',\n",
    " 'wells',\n",
    " 'toentry',\n",
    " 'confrontation',\n",
    " 'crane_ranger',\n",
    " 'flag_girl',\n",
    " 'tomap',\n",
    " 'tostacks',\n",
    " 'tobasement',\n",
    " 'archivist_glasses',\n",
    " 'boss',\n",
    " 'journals',\n",
    " 'seescratches',\n",
    " 'groupconvo_flag',\n",
    " 'teddy',\n",
    " 'expert',\n",
    " 'businesscards',\n",
    " 'ch3start',\n",
    " 'tunic.historicalsociety',\n",
    " 'tofrontdesk',\n",
    " 'savedteddy',\n",
    " 'plaque',\n",
    " 'glasses',\n",
    " 'tunic.drycleaner',\n",
    " 'reader_flag',\n",
    " 'tunic.library',\n",
    " 'tracks',\n",
    " 'tunic.capitol_2',\n",
    " 'reader',\n",
    " 'directory',\n",
    " 'tunic.capitol_1',\n",
    " 'journals.pic_0.next',\n",
    " 'unlockdoor',\n",
    " 'tunic',\n",
    " 'tunic.kohlcenter',\n",
    " 'tunic.humanecology',\n",
    " 'colorbook',\n",
    " 'logbook',\n",
    " 'businesscards.card_0.next',\n",
    " 'journals.hub.topics',\n",
    " 'journals.pic_1.next',\n",
    " 'journals_flag',\n",
    " 'reader.paper0.next',\n",
    " 'tracks.hub.deer',\n",
    " 'reader_flag.paper0.next',\n",
    " 'journals.pic_2.next',\n",
    " 'tomicrofiche',\n",
    " 'journals_flag.pic_0.bingo',\n",
    " 'tocloset_dirty',\n",
    " 'businesscards.card_1.next',\n",
    " 'tunic.wildlife',\n",
    " 'tunic.hub.slip',\n",
    " 'tocage',\n",
    " 'journals.pic_2.bingo',\n",
    " 'tocollectionflag',\n",
    " 'tocollection',\n",
    " 'chap4_finale_c',\n",
    " 'lockeddoor',\n",
    " 'journals_flag.hub.topics',\n",
    " 'reader_flag.paper2.bingo',\n",
    " 'photo',\n",
    " 'tunic.flaghouse',\n",
    " 'reader.paper1.next',\n",
    " 'directory.closeup.archivist',\n",
    " 'businesscards.card_bingo.next',\n",
    " 'remove_cup',\n",
    " 'journals_flag.pic_0.next',\n",
    " 'coffee',\n",
    " 'key',\n",
    " 'reader_flag.paper1.next',\n",
    " 'tohallway',\n",
    " 'outtolunch',\n",
    " 'journals_flag.hub.topics_old',\n",
    " 'journals_flag.pic_1.next',\n",
    " 'reader.paper2.next',\n",
    " 'reader_flag.paper2.next',\n",
    " 'journals_flag.pic_1.bingo',\n",
    " 'journals_flag.pic_2.next',\n",
    " 'journals_flag.pic_2.bingo',\n",
    " 'reader.paper0.prev',\n",
    " 'reader_flag.paper0.prev',\n",
    " 'reader.paper2.prev',\n",
    " 'reader.paper1.prev',\n",
    " 'reader_flag.paper2.prev',\n",
    " 'reader_flag.paper1.prev',\n",
    " 'journals_flag.pic_0_old.next',\n",
    " 'journals_flag.pic_1_old.next',\n",
    " 'block_nelson',\n",
    " 'journals_flag.pic_2_old.next',\n",
    " 'need_glasses',\n",
    " 'fox'],\n",
    "                 }\n",
    "\n",
    "sub_room_lists = {'0-4': ['tunic.historicalsociety.entry',\n",
    " 'tunic.historicalsociety.stacks',\n",
    " 'tunic.historicalsociety.basement',\n",
    " 'tunic.kohlcenter.halloffame',\n",
    " 'tunic.historicalsociety.collection',\n",
    " 'tunic.historicalsociety.closet',\n",
    " 'tunic.capitol_0.hall'],\n",
    "                  '5-12': ['tunic.historicalsociety.entry',\n",
    " 'tunic.library.frontdesk',\n",
    " 'tunic.historicalsociety.frontdesk',\n",
    " 'tunic.historicalsociety.stacks',\n",
    " 'tunic.historicalsociety.closet_dirty',\n",
    " 'tunic.humanecology.frontdesk',\n",
    " 'tunic.historicalsociety.basement',\n",
    " 'tunic.kohlcenter.halloffame',\n",
    " 'tunic.library.microfiche',\n",
    " 'tunic.drycleaner.frontdesk',\n",
    " 'tunic.historicalsociety.collection',\n",
    " 'tunic.capitol_1.hall',\n",
    " 'tunic.capitol_0.hall'],\n",
    "                  '13-22': ['tunic.historicalsociety.entry',\n",
    " 'tunic.wildlife.center',\n",
    " 'tunic.historicalsociety.cage',\n",
    " 'tunic.library.frontdesk',\n",
    " 'tunic.historicalsociety.frontdesk',\n",
    " 'tunic.historicalsociety.stacks',\n",
    " 'tunic.historicalsociety.closet_dirty',\n",
    " 'tunic.humanecology.frontdesk',\n",
    " 'tunic.historicalsociety.basement',\n",
    " 'tunic.kohlcenter.halloffame',\n",
    " 'tunic.library.microfiche',\n",
    " 'tunic.drycleaner.frontdesk',\n",
    " 'tunic.historicalsociety.collection',\n",
    " 'tunic.flaghouse.entry',\n",
    " 'tunic.historicalsociety.collection_flag',\n",
    " 'tunic.capitol_1.hall',\n",
    " 'tunic.capitol_2.hall'],\n",
    "                 }\n",
    "\n",
    "\n",
    "sub_text_lists = {'0-4': ['tunic.historicalsociety.entry.groupconvo',\n",
    " 'tunic.historicalsociety.collection.cs',\n",
    " 'tunic.historicalsociety.collection.gramps.found',\n",
    " 'tunic.historicalsociety.closet.gramps.intro_0_cs_0',\n",
    " 'tunic.historicalsociety.closet.teddy.intro_0_cs_0',\n",
    " 'tunic.historicalsociety.closet.intro',\n",
    " 'tunic.historicalsociety.closet.retirement_letter.hub',\n",
    " 'tunic.historicalsociety.collection.tunic.slip',\n",
    " 'tunic.kohlcenter.halloffame.plaque.face.date',\n",
    " 'tunic.kohlcenter.halloffame.togrampa',\n",
    " 'tunic.historicalsociety.collection.gramps.lost',\n",
    " 'tunic.historicalsociety.closet.notebook',\n",
    " 'tunic.historicalsociety.basement.janitor',\n",
    " 'tunic.historicalsociety.stacks.outtolunch',\n",
    " 'tunic.historicalsociety.closet.photo',\n",
    " 'tunic.historicalsociety.collection.tunic',\n",
    " 'tunic.historicalsociety.closet.teddy.intro_0_cs_5',\n",
    " 'tunic.historicalsociety.entry.wells.talktogramps',\n",
    " 'tunic.historicalsociety.entry.boss.talktogramps',\n",
    " 'tunic.historicalsociety.closet.doorblock',\n",
    " 'tunic.historicalsociety.entry.block_tomap2',\n",
    " 'tunic.historicalsociety.entry.block_tocollection',\n",
    " 'tunic.historicalsociety.entry.block_tomap1',\n",
    " 'tunic.historicalsociety.collection.gramps.look_0',\n",
    " 'tunic.kohlcenter.halloffame.block_0',\n",
    " 'tunic.capitol_0.hall.chap1_finale_c',\n",
    " 'tunic.historicalsociety.entry.gramps.hub'],\n",
    "               '5-12': ['tunic.historicalsociety.frontdesk.archivist.newspaper',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.have_glass',\n",
    " 'tunic.drycleaner.frontdesk.worker.hub',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.news',\n",
    " 'tunic.humanecology.frontdesk.worker.intro',\n",
    " 'tunic.library.frontdesk.worker.hello',\n",
    " 'tunic.library.frontdesk.worker.wells',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.hello',\n",
    " 'tunic.historicalsociety.closet_dirty.trigger_scarf',\n",
    " 'tunic.drycleaner.frontdesk.worker.done',\n",
    " 'tunic.historicalsociety.closet_dirty.what_happened',\n",
    " 'tunic.historicalsociety.stacks.journals.pic_2.bingo',\n",
    " 'tunic.humanecology.frontdesk.worker.badger',\n",
    " 'tunic.historicalsociety.closet_dirty.trigger_coffee',\n",
    " 'tunic.drycleaner.frontdesk.logbook.page.bingo',\n",
    " 'tunic.library.microfiche.reader.paper2.bingo',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.helpclean',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.have_glass_recap',\n",
    " 'tunic.historicalsociety.frontdesk.magnify',\n",
    " 'tunic.humanecology.frontdesk.businesscards.card_bingo.bingo',\n",
    " 'tunic.library.frontdesk.wellsbadge.hub',\n",
    " 'tunic.capitol_1.hall.boss.haveyougotit',\n",
    " 'tunic.historicalsociety.basement.janitor',\n",
    " 'tunic.historicalsociety.closet_dirty.photo',\n",
    " 'tunic.historicalsociety.stacks.outtolunch',\n",
    " 'tunic.library.frontdesk.worker.wells_recap',\n",
    " 'tunic.capitol_0.hall.boss.talktogramps',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.archivist',\n",
    " 'tunic.historicalsociety.closet_dirty.door_block_talk',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.need_glass_0',\n",
    " 'tunic.historicalsociety.frontdesk.block_magnify',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.foundtheodora',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.nothing',\n",
    " 'tunic.historicalsociety.closet_dirty.door_block_clean',\n",
    " 'tunic.library.frontdesk.worker.hello_short',\n",
    " 'tunic.historicalsociety.stacks.block',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.need_glass_1',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.newspaper_recap',\n",
    " 'tunic.drycleaner.frontdesk.worker.done2',\n",
    " 'tunic.humanecology.frontdesk.block_0',\n",
    " 'tunic.library.frontdesk.worker.preflag',\n",
    " 'tunic.drycleaner.frontdesk.worker.takealook',\n",
    " 'tunic.library.frontdesk.worker.droppedbadge',\n",
    " 'tunic.library.microfiche.block_0',\n",
    " 'tunic.library.frontdesk.block_badge',\n",
    " 'tunic.library.frontdesk.block_badge_2',\n",
    " 'tunic.capitol_1.hall.chap2_finale_c',\n",
    " 'tunic.drycleaner.frontdesk.block_0',\n",
    " 'tunic.humanecology.frontdesk.block_1',\n",
    " 'tunic.drycleaner.frontdesk.block_1'],\n",
    "               '13-22': ['tunic.historicalsociety.cage.confrontation',\n",
    " 'tunic.wildlife.center.crane_ranger.crane',\n",
    " 'tunic.wildlife.center.wells.nodeer',\n",
    " 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation',\n",
    " 'tunic.historicalsociety.basement.seescratches',\n",
    " 'tunic.flaghouse.entry.flag_girl.hello',\n",
    " 'tunic.historicalsociety.basement.ch3start',\n",
    " 'tunic.historicalsociety.entry.groupconvo_flag',\n",
    " 'tunic.historicalsociety.collection_flag.gramps.flag',\n",
    " 'tunic.historicalsociety.basement.savedteddy',\n",
    " 'tunic.library.frontdesk.worker.nelson',\n",
    " 'tunic.wildlife.center.expert.removed_cup',\n",
    " 'tunic.library.frontdesk.worker.flag',\n",
    " 'tunic.historicalsociety.entry.boss.flag',\n",
    " 'tunic.flaghouse.entry.flag_girl.symbol',\n",
    " 'tunic.wildlife.center.wells.animals',\n",
    " 'tunic.historicalsociety.cage.glasses.afterteddy',\n",
    " 'tunic.historicalsociety.cage.teddy.trapped',\n",
    " 'tunic.historicalsociety.cage.unlockdoor',\n",
    " 'tunic.historicalsociety.stacks.journals.pic_2.bingo',\n",
    " 'tunic.historicalsociety.entry.wells.flag',\n",
    " 'tunic.humanecology.frontdesk.worker.badger',\n",
    " 'tunic.historicalsociety.stacks.journals_flag.pic_0.bingo',\n",
    " 'tunic.historicalsociety.entry.directory.closeup.archivist',\n",
    " 'tunic.capitol_2.hall.boss.haveyougotit',\n",
    " 'tunic.wildlife.center.wells.nodeer_recap',\n",
    " 'tunic.historicalsociety.cage.glasses.beforeteddy',\n",
    " 'tunic.wildlife.center.expert.recap',\n",
    " 'tunic.historicalsociety.stacks.journals_flag.pic_1.bingo',\n",
    " 'tunic.historicalsociety.cage.lockeddoor',\n",
    " 'tunic.historicalsociety.stacks.journals_flag.pic_2.bingo',\n",
    " 'tunic.wildlife.center.remove_cup',\n",
    " 'tunic.wildlife.center.tracks.hub.deer',\n",
    " 'tunic.historicalsociety.frontdesk.key',\n",
    " 'tunic.library.microfiche.reader_flag.paper2.bingo',\n",
    " 'tunic.flaghouse.entry.colorbook',\n",
    " 'tunic.wildlife.center.coffee',\n",
    " 'tunic.historicalsociety.collection_flag.gramps.recap',\n",
    " 'tunic.wildlife.center.wells.animals2',\n",
    " 'tunic.flaghouse.entry.flag_girl.symbol_recap',\n",
    " 'tunic.historicalsociety.closet_dirty.photo',\n",
    " 'tunic.historicalsociety.stacks.outtolunch',\n",
    " 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap',\n",
    " 'tunic.historicalsociety.entry.boss.flag_recap',\n",
    " 'tunic.capitol_1.hall.boss.writeitup',\n",
    " 'tunic.library.frontdesk.worker.nelson_recap',\n",
    " 'tunic.historicalsociety.entry.wells.flag_recap',\n",
    " 'tunic.drycleaner.frontdesk.worker.done2',\n",
    " 'tunic.library.frontdesk.worker.flag_recap',\n",
    " 'tunic.library.frontdesk.worker.preflag',\n",
    " 'tunic.historicalsociety.basement.gramps.seeyalater',\n",
    " 'tunic.flaghouse.entry.flag_girl.hello_recap',\n",
    " 'tunic.historicalsociety.basement.gramps.whatdo',\n",
    " 'tunic.library.frontdesk.block_nelson',\n",
    " 'tunic.historicalsociety.cage.need_glasses',\n",
    " 'tunic.capitol_2.hall.chap4_finale_c',\n",
    " 'tunic.wildlife.center.fox.concern']\n",
    "              }\n",
    "\n",
    "\n",
    "SUB_LEVELS = {'0-4': [1, 2, 3, 4],\n",
    "              '5-12': [5, 6, 7, 8, 9, 10, 11, 12],\n",
    "              '13-22': [13, 14, 15, 16, 17, 18, 19, 20, 21, 22]}\n",
    "level_groups = [\"0-4\", \"5-12\", \"13-22\"]\n",
    "\n",
    "\n",
    "def feature_engineer(x, grp, use_extra, feature_suffix):\n",
    "    LEVELS = SUB_LEVELS[grp]\n",
    "    text_lists = sub_text_lists[grp]\n",
    "    room_lists = sub_room_lists[grp]\n",
    "    fqid_lists = sub_fqid_lists[grp]\n",
    "    aggs = [\n",
    "\n",
    "        pl.col(\"index\").count().alias(f\"session_number_{feature_suffix}\"),\n",
    "\n",
    "        *[pl.col('index').filter(pl.col('text').str.contains(c)).count().alias(f'word_{c}') for c in DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).mean().alias(f'word_mean_{c}') for c in\n",
    "          DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).std().alias(f'word_std_{c}') for c in\n",
    "          DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).max().alias(f'word_max_{c}') for c in\n",
    "          DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).min().alias(f'word_min_{c}') for c in\n",
    "          DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).sum().alias(f'word_sum_{c}') for c in\n",
    "          DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).median().alias(f'word_median_{c}') for c\n",
    "          in DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).skew().alias(f'word_skew_{c}') for c\n",
    "          in DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).kurtosis().alias(f'word_kurtosis_{c}') for c\n",
    "          in DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).quantile(0.25).alias(f'word_quant25_{c}') for c\n",
    "          in DIALOGS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter((pl.col('text').str.contains(c))).quantile(0.75).alias(f'word_quant75_{c}') for c\n",
    "          in DIALOGS],\n",
    "\n",
    "\n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique_{feature_suffix}\") for c in CATS],\n",
    "\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).std().alias(f\"{c}_std_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).median().alias(f\"{c}_median_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).skew().alias(f\"{c}_skew_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).kurtosis().alias(f\"{c}_kurtosis_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.25).alias(f\"{c}_quant25_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.75).alias(f\"{c}_quant75_{feature_suffix}\") for c in NUMS],\n",
    "\n",
    "        *[pl.col(\"fqid\").filter(pl.col(\"fqid\") == c).count().alias(f\"{c}_fqid_counts{feature_suffix}\")\n",
    "          for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in fqid_lists],\n",
    "\n",
    "\n",
    "        *[pl.col(\"text_fqid\").filter(pl.col(\"text_fqid\") == c).count().alias(f\"{c}_text_fqid_counts{feature_suffix}\")\n",
    "          for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\")\n",
    "          for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in text_lists],\n",
    "\n",
    "        *[pl.col(\"room_fqid\").filter(pl.col(\"room_fqid\") == c).count().alias(f\"{c}_room_fqid_counts{feature_suffix}\")\n",
    "          for c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "\n",
    "        *[pl.col(\"event_name\").filter(pl.col(\"event_name\") == c).count().alias(f\"{c}_event_name_counts{feature_suffix}\")\n",
    "          for c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\")\n",
    "          for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).median().alias(\n",
    "            f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "\n",
    "        *[pl.col(\"name\").filter(pl.col(\"name\") == c).count().alias(f\"{c}_name_counts{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in name_feature],\n",
    "\n",
    "        *[pl.col(\"level\").filter(pl.col(\"level\") == c).count().alias(f\"{c}_LEVEL_count{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c\n",
    "          in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in LEVELS],\n",
    "\n",
    "        *[pl.col(\"level_group\").filter(pl.col(\"level_group\") == c).count().alias(\n",
    "            f\"{c}_LEVEL_group_count{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\")\n",
    "          for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).median().alias(\n",
    "            f\"{c}_ET_median_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).min().alias(f\"{c}_ET_min_{feature_suffix}\") for\n",
    "          c in level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).skew().alias(f\"{c}_ET_skew_{feature_suffix}\") for\n",
    "          c in level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).kurtosis().alias(f\"{c}_ET_kurtosis_{feature_suffix}\") for\n",
    "          c in level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).quantile(0.25).alias(f\"{c}_ET_quant25_{feature_suffix}\") for\n",
    "          c in level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).quantile(0.75).alias(f\"{c}_ET_quant75_{feature_suffix}\") for\n",
    "          c in level_groups]\n",
    "\n",
    "    ]\n",
    "    # df = x.groupby(['session_id']).agg(aggs).sort_values(\"session_id\")\n",
    "\n",
    "    df = x.with_columns(COLUMNS).groupby(['session_id'], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "\n",
    "    # Time features - Year, month, ...\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[:2])).alias('year'),\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[2:4])+1).alias('month'),\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[4:6])).alias('day'),\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[6:8])).alias('hour'),\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[8:10])).alias('minute'),\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[10:12])).alias('second'),\n",
    "        pl.col(\"session_id\").apply(lambda x: int(str(x)[12:])).alias('id_anonymous'),\n",
    "    )\n",
    "\n",
    "    if use_extra:\n",
    "        if grp == '5-12':\n",
    "            aggs = [\n",
    "                pl.col(\"elapsed_time\").filter((pl.col(\"text\") == \"Here's the log book.\")\n",
    "                                              | (pl.col(\"fqid\") == 'logbook.page.bingo'))\n",
    "                    .apply(lambda s: s.max() - s.min()).alias(\"logbook_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    (pl.col(\"text\") == \"Here's the log book.\") | (pl.col(\"fqid\") == 'logbook.page.bingo')).apply(\n",
    "                    lambda s: s.max() - s.min()).alias(\"logbook_bingo_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (\n",
    "                            pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"reader_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (\n",
    "                        pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"reader_bingo_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (\n",
    "                            pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"journals_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (\n",
    "                        pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"journals_bingo_indexCount\"),\n",
    "            ]\n",
    "            #tmp = x.groupby(['session_id']).agg(aggs).sort_values(\"session_id\")\n",
    "\n",
    "            tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "            df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "        if grp == '13-22':\n",
    "            aggs = [\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_indexCount\")\n",
    "            ]\n",
    "            #tmp = x.groupby(['session_id']).agg(aggs).sort_values(\"session_id\")\n",
    "\n",
    "            tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "            df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "    return df.to_pandas(), x.with_columns(COLUMNS).to_pandas()\n",
    "\n",
    "def time_feature(train):\n",
    "    train = train.reset_index()\n",
    "    q = (\n",
    "        pl.from_pandas(train)\n",
    "          .lazy()\n",
    "          .with_columns([\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[:2])).alias('year'),#.astype(np.uint8)\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[2:4])+1).alias('month'),#.astype(np.uint8)\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[4:6])).alias('day'),#.astype(np.uint8)\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[6:8])).alias('hour'),#.astype(np.uint8)\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[8:10])).alias('minute'),#.astype(np.uint8)\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[10:12])).alias('second'),#.astype(np.uint8)\n",
    "            pl.col(\"session_id\").apply(lambda x: int(str(x)[12:])).alias('id_anonymous'),#.astype(np.uint8)\n",
    "        ])\n",
    "    )\n",
    "    # train[\"year\"] = train.with_columns(\"session_id\").apply(lambda x: int(str(x)[:2]))#.astype(np.uint8)\n",
    "    # train[\"month\"] = train[\"session_id\"].apply(lambda x: int(str(x)[2:4])+1)#.astype(np.uint8)\n",
    "    # train[\"day\"] = train[\"session_id\"].apply(lambda x: int(str(x)[4:6]))#.astype(np.uint8)\n",
    "    # train[\"hour\"] = train[\"session_id\"].apply(lambda x: int(str(x)[6:8]))#.astype(np.uint8)\n",
    "    # train[\"minute\"] = train[\"session_id\"].apply(lambda x: int(str(x)[8:10]))#.astype(np.uint8)\n",
    "    # train[\"second\"] = train[\"session_id\"].apply(lambda x: int(str(x)[10:12]))#.astype(np.uint8)\n",
    "    # train[\"id_anonymous\"] = train[\"session_id\"].apply(lambda x: int(str(x)[12:]))#.astype(np.uint8)\n",
    "    \n",
    "    # time features\n",
    "    # df = pl.from_pandas(train)\n",
    "    # aggs = [\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[:2])).alias('year'),\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[2:4])+1).alias('month'),\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[4:6])).alias('day'),\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[6:8])).alias('hour'),\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[8:10])).alias('minute'),\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[10:12])).alias('second'),\n",
    "    #     pl.col('session_id').apply(lambda x: int(str(x)[12:])).alias('id_anonymous'),\n",
    "    # ]\n",
    "\n",
    "    return q.collect().to_pandas().set_index('session_id')\n",
    "\n",
    "\n",
    "def new_page(X, grp):   # 여기서 더 일반적인 feature를 추출할 수 있을듯. page 0 을 들른 유저들은 new_page 0, 아닌 유저들은 1로 했는데, 그냥 조회한 page 수를 feature로 넘겨주면 되지않을까?\n",
    "    '''\n",
    "    X= revised_train dataset\n",
    "    '''\n",
    "    # 이상치 session_id 추출\n",
    "    if grp == '5-12':\n",
    "        session_2=X[X.page==0].session_id.unique().tolist()\n",
    "        X.loc[X['session_id'].isin(session_2), 'new_page'] = 0\n",
    "        X.loc[~X['session_id'].isin(session_2), 'new_page'] = 1\n",
    "    \n",
    "    if grp == '13-22':\n",
    "        session_3=X[(X.page==0)|(X.page==1)|(X.page==2)].session_id.unique().tolist()\n",
    "        X.loc[X['session_id'].isin(session_3), 'new_page'] = 0\n",
    "        X.loc[~X['session_id'].isin(session_3), 'new_page'] = 1\n",
    "    \n",
    "    return X.groupby(['session_id']).first().reset_index()\n",
    "\n",
    "# https://www.kaggle.com/code/glipko/recap-texts#Data-Extraction-\n",
    "def text_cnt(x, revised_train):\n",
    "    \n",
    "    x['in_the_same_dialogue'] = x['text_fqid'].shift() # 한칸씩 뒤로\n",
    "    x['in_the_same_dialogue'] = x['text_fqid'] == x['in_the_same_dialogue']\n",
    "\n",
    "    dialogue_sequence = x[~x['in_the_same_dialogue']] # 겹치지 않는 아이들\n",
    "    dialogue_sequence = dialogue_sequence[~dialogue_sequence['text_fqid'].isna()]\n",
    "    dialogue_sequence = dialogue_sequence[(dialogue_sequence['event_name'] == 'observation_click') | \\\n",
    "                                      (dialogue_sequence['event_name'] == 'person_click')]\n",
    "    dialogue_sequence = dialogue_sequence.drop(columns=['text', 'in_the_same_dialogue', 'elapsed_time'], errors='ignore')\n",
    "\n",
    "    dialogues = x[x['event_name'] == 'person_click']['text_fqid'].unique()\n",
    "    recap_dialogues = []\n",
    "    for dialogue in dialogues:\n",
    "        if('recap' in dialogue or 'lost' in dialogue):\n",
    "            recap_dialogues.append(dialogue)\n",
    "\n",
    "\n",
    "    observations = x[x['event_name'] == 'observation_click']['text_fqid'].unique()\n",
    "    recap_observations = []\n",
    "    for observation in observations:\n",
    "        if('block' in observation):\n",
    "            recap_observations.append(observation)\n",
    "\n",
    "\n",
    "    dialogue_sequence = dialogue_sequence[dialogue_sequence['text_fqid'].isin(recap_observations) | \\\n",
    "                        dialogue_sequence['text_fqid'].isin(recap_dialogues)]\n",
    "\n",
    "    session_event_recap = dialogue_sequence.groupby(['session_id', 'event_name']) \\\n",
    "                                        .size() \\\n",
    "                                        .reset_index() \\\n",
    "                                        .rename(columns={0:'recap_reading'})\n",
    "\n",
    "    session_event_recap = session_event_recap[(session_event_recap['event_name'] == 'observation_click') | \\\n",
    "                    (session_event_recap['event_name'] == 'person_click')]\n",
    "\n",
    "    session_recap = session_event_recap.groupby('session_id')['recap_reading'].sum()\n",
    "\n",
    "    texts = x[(~x['text'].isna()) & (x['text'] != 'undefined')]\n",
    "    reading = texts.groupby('session_id').size()\n",
    "    text_feature=pd.concat([session_recap,reading], axis=1)\n",
    "    text_feature.columns=['recap_reading', 'reading_cnt']\n",
    "    \n",
    "    # revised_train = pd.merge(x, revised_train, on='session_id', how='left')\n",
    "    \n",
    "    return pd.merge(revised_train, text_feature, on='session_id', how='left').set_index('session_id')\n",
    "\n",
    "\n",
    "def feature_quest(new_train, train, q):\n",
    "    train_q = new_train.copy()\n",
    "    texts = {\n",
    "        1: [\"Yes! This cool old slip from 1916.\", \n",
    "             \"Go ahead, take a peek at the shirt!\", \n",
    "             \"I'll be at the Capitol. Let me know if you find anything!\", \n",
    "             \"We need to talk about that missing paperwork.\", \n",
    "             \"The slip is from 1916 but the team didn't start until 1974!\"], \n",
    "         2: [\"It's already all done!\", \n",
    "             \"Gramps is the best historian ever!\"], \n",
    "         3: [\"I suppose historians are boring, too?\" \n",
    "             \"Why don't you head to the Basketball Center and rustle up some clues?\", \n",
    "             \"We need to talk about that missing paperwork.\"],    \n",
    "        \n",
    "         4: ['I need to find the owner of this slip.',\n",
    "             'She led marches and helped women get the right to vote!', \n",
    "             \"Here's a call number to find more info in the Stacks.\", \n",
    "             \"What was Wells doing here?\"],\n",
    "\n",
    "         5: [\"Your gramps is awesome! Always full of stories.\",\n",
    "             \"Here's a call number to find more info in the Stacks.\", \n",
    "             \"Where did you get that coffee?\"],         \n",
    "        \n",
    "         6: [\"Oh, that's from Bean Town.\", \n",
    "             \"Wells? I knew it!\"], \n",
    "           \n",
    "         7: [\"Try not to panic, Jo.\",\n",
    "             \"I've got a stack of business cards from my favorite cleaners.\",\n",
    "             \"Check out our microfiche. It's right through that door.\", \n",
    "             \"I'm afraid my papers have gone missing in this mess.\", \n",
    "             \"Nope. But Youmans and other suffragists worked hard to change that.\"], \n",
    "            \n",
    "         8: [\"What should I do first?\",\n",
    "             \"Thanks to them, Wisconsin was the first state to approve votes for women!\"], \n",
    "\n",
    "         9: [ \"Can you help me? I need to find the owner of this slip.\",\n",
    "             'Looks like a dry cleaning receipt.',\n",
    "             \"I knew I could count on you, Jo!\", \n",
    "             \"Nope, that's from Bean Town. I only drink Holdgers!\"], \n",
    "\n",
    "         10:[\"I love these photos of me and Teddy.\"\n",
    "             'Your gramps is awesome! Always full of stories.',\n",
    "             \"Nope. But Youmans and other suffragists worked hard to change that.\", \n",
    "             \"Right outside the door.\", \n",
    "             \"Do you have any info on Theodora Youmans?\"], \n",
    "                   \n",
    "         11:[\"I ran into Wells there this morning\",\n",
    "             'Your gramps is awesome! Always full of stories.',\n",
    "             \"Wait a sec. Women couldn't vote?!\", \n",
    "             \"I've got a stack of business cards from my favorite cleaners.\",\n",
    "             \"An old shirt? Try the university.\"],  \n",
    "         12:[],\n",
    "         13:[],        \n",
    "         14:[],\n",
    "         15:[],\n",
    "         16:[],\n",
    "         17:[],\n",
    "         18:[]\n",
    "        }\n",
    "    i = 0\n",
    "    for text in texts[q]:\n",
    "        i += 1\n",
    "        train_q['text' + str(i)] = train[train['text'] == text].groupby(['session_id'])['elapsed_time_diff'].sum()\n",
    "    \n",
    "    fqids = {\n",
    "         1: ['directory'], \n",
    "         2: ['notebook','chap1_finale_c'], \n",
    "         3: ['tostacks','doorblock'], \n",
    "         4: ['journals.pic_1.next', 'businesscards.card_1.next', 'block'], \n",
    "         5: ['janitor', 'journals.pic_2.next'], \n",
    "         6: ['businesscards', 'journals.pic_0.next','tobasement', 'logbook.page.bingo', 'tohallway'],  \n",
    "         7: ['journals.pic_1.next','reader.paper2.bingo','businesscards.card_bingo.next', \n",
    "             'logbook.page.bingo', 'tunic.kohlcenter'],  \n",
    "         8: ['reader.paper2.bingo'],  \n",
    "         9: ['journals.pic_1.next','businesscards.card_bingo.bingo', 'reader'],  \n",
    "         10:['tunic.kohlcenter','magnify','block','journals.pic_1.next', 'journals'], \n",
    "         11:['tostacks','block_magnify','block','businesscards.card_bingo.next'], \n",
    "         12:['businesscards.card_1.next','tofrontdesk'],  \n",
    "         13:['tocloset_dirty','reader.paper1.next'], \n",
    "         14:['tracks'], \n",
    "         15:['groupconvo_flag'], \n",
    "         16:['savedteddy'], \n",
    "         17:['journals_flag.pic_0.next'], \n",
    "         18:['chap4_finale_c'], \n",
    "        }\n",
    "    for fqid in fqids[q]:\n",
    "        train_q['t_fqid_' + fqid] = train[train['fqid'] == fqid].groupby(['session_id'])['elapsed_time_diff'].sum()\n",
    "\n",
    "    text_fqids = {\n",
    "        1:[],\n",
    "        2:['tunic.historicalsociety.collection.gramps.found'],\n",
    "        3:[],\n",
    "        4: ['tunic.humanecology.frontdesk.worker.intro',\n",
    "            'tunic.library.frontdesk.worker.wells', \n",
    "            'tunic.library.frontdesk.worker.hello'], \n",
    "        5: ['tunic.humanecology.frontdesk.worker.intro',\n",
    "            'tunic.historicalsociety.closet_dirty.gramps.helpclean',\n",
    "            'tunic.historicalsociety.closet_dirty.gramps.news'],     \n",
    "        6: ['tunic.humanecology.frontdesk.worker.intro',\n",
    "            'tunic.historicalsociety.frontdesk.archivist.foundtheodora',\n",
    "            'tunic.historicalsociety.closet_dirty.trigger_coffee', \n",
    "            'tunic.historicalsociety.closet_dirty.gramps.archivist'], \n",
    "        7: ['tunic.historicalsociety.closet_dirty.door_block_talk',\n",
    "            'tunic.drycleaner.frontdesk.worker.hub',\n",
    "            'tunic.historicalsociety.closet_dirty.trigger_coffee'], \n",
    "        8: ['tunic.humanecology.frontdesk.worker.intro',\n",
    "            'tunic.historicalsociety.frontdesk.magnify', \n",
    "            'tunic.historicalsociety.closet_dirty.trigger_coffee'], \n",
    "        9: ['tunic.historicalsociety.frontdesk.archivist.hello',\n",
    "            'tunic.library.frontdesk.worker.wells', \n",
    "            'tunic.historicalsociety.frontdesk.archivist.foundtheodora'], \n",
    "        10: ['tunic.library.frontdesk.worker.wells',\n",
    "            'tunic.historicalsociety.frontdesk.archivist.have_glass_recap',\n",
    "             'tunic.historicalsociety.closet_dirty.gramps.news'], \n",
    "        11: ['tunic.historicalsociety.frontdesk.archivist.newspaper_recap',\n",
    "             'tunic.historicalsociety.closet_dirty.gramps.archivist'], \n",
    "        12:[],\n",
    "        13:['tunic.drycleaner.frontdesk.logbook.page.bingo'],\n",
    "        14: ['tunic.flaghouse.entry.flag_girl.symbol_recap', \n",
    "             'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap'],\n",
    "        15:['tunic.flaghouse.entry.colorbook'], \n",
    "        16:['tunic.library.frontdesk.worker.nelson'], \n",
    "        17:['tunic.historicalsociety.entry.wells.flag'], \n",
    "        18:['tunic.flaghouse.entry.flag_girl.symbol_recap'], \n",
    "    }\n",
    "    for text_fqid in text_fqids[q]:\n",
    "        maska = train['text_fqid'] == text_fqid\n",
    "        train_q['t_text_fqid_' + text_fqid] = train[maska].groupby(['session_id'])['elapsed_time_diff'].sum()       \n",
    "        train_q['l_text_fqid_' + text_fqid] = train[train['text_fqid'] == text_fqid].groupby(['session_id'])['index'].count()\n",
    "\n",
    "\n",
    "    room_lvls = {\n",
    "         1: [['tunic.capitol_0.hall',4],['tunic.historicalsociety.collection',3],\n",
    "            ['tunic.historicalsociety.entry',1],['tunic.historicalsociety.collection', 2]], \n",
    "         2: [],\n",
    "         3: [['tunic.capitol_0.hall',4]], \n",
    "         4: [['tunic.historicalsociety.frontdesk',12], \n",
    "             ['tunic.historicalsociety.stacks',7]], \n",
    "         5: [['tunic.historicalsociety.stacks',12]],  \n",
    "         6: [['tunic.drycleaner.frontdesk',8],  \n",
    "             ['tunic.library.microfiche',9]], \n",
    "         7: [['tunic.library.frontdesk',10]], \n",
    "         8: [['tunic.kohlcenter.halloffame', 11], \n",
    "             ['tunic.kohlcenter.halloffame',6]], \n",
    "         9: [['tunic.capitol_1.hall', 12], \n",
    "             ['tunic.historicalsociety.collection',12]],\n",
    "         10:[['tunic.humanecology.frontdesk',7]], \n",
    "         11:[['tunic.drycleaner.frontdesk',9], \n",
    "             ['tunic.historicalsociety.collection',6]], \n",
    "         12:[['tunic.historicalsociety.stacks',6],\n",
    "             ['tunic.historicalsociety.frontdesk', 7],\n",
    "             ['tunic.historicalsociety.closet_dirty',11], \n",
    "             ['tunic.historicalsociety.frontdesk', 12]], \n",
    "         13:[['tunic.library.microfiche', 9], \n",
    "             ['tunic.historicalsociety.stacks', 11],\n",
    "             ['tunic.library.frontdesk', 10], \n",
    "             ['tunic.historicalsociety.entry', 5]], \n",
    "         14:[['tunic.historicalsociety.closet_dirty',17],\n",
    "             ['tunic.historicalsociety.entry',15]], \n",
    "         15:[['tunic.historicalsociety.entry',15],\n",
    "             ['tunic.library.frontdesk',20]], \n",
    "         16:[['tunic.library.frontdesk', 20],\n",
    "             ['tunic.wildlife.center',19]], \n",
    "         17:[['tunic.wildlife.center', 19],\n",
    "             ['tunic.historicalsociety.stacks', 21]], \n",
    "         18:[['tunic.wildlife.center', 22]], \n",
    "        }\n",
    "    for rl in room_lvls[q]:\n",
    "        nam = rl[0]+str(rl[1])\n",
    "        maska = (train['room_fqid'] == rl[0])&(train['level'] == rl[1])\n",
    "        train_q['t_' + nam] = train[maska].groupby(['session_id'])['elapsed_time_diff'].sum()\n",
    "        train_q['l_' + nam] = train[maska].groupby(['session_id'])['index'].count()\n",
    "\n",
    "    return train_q\n",
    "\n",
    "\n",
    "def load_targets(args):\n",
    "    targets = pd.read_parquet(args.target)\n",
    "    # targets = pd.read_csv(args.target)\n",
    "    targets[\"session\"] = targets[\"session_id\"].str.split(\"_\",expand = True)[0]\n",
    "    targets[\"session\"] = targets[\"session\"].astype(int)\n",
    "    targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "    return targets\n",
    "\n",
    "\n",
    "def preprocessing(df, grp):\n",
    "    # start, end = map(int,grp.split('-'))\n",
    "    # kol_lvl = (df.groupby(['session_id'])['level'].agg('nunique') < end - start + 1)\n",
    "    # list_session = kol_lvl[kol_lvl].index\n",
    "    # df = df[~df['session_id'].isin(list_session)]\n",
    "    # df = delt_time_def(df) # elapsed_time_diff feature와 겹치므로 이후 수정하기\n",
    "    train_, df = feature_engineer(pl.from_pandas(df), grp, use_extra=False, feature_suffix='')\n",
    "    # recap text count \\w join\n",
    "    train = text_cnt(df, train_)\n",
    "\n",
    "    # add year, month, day etc. - incorporate into feature_engineer\n",
    "    # train = time_feature(train)\n",
    "\n",
    "    \n",
    "    # df = new_page(df, grp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train, df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import platform\n",
    "import pickle\n",
    "\n",
    "def parse_args():\n",
    "\n",
    "    if platform.system() == 'Linux':\n",
    "        DIR = \"/home/wooseok/Python_lab/kaggle/gameplay/student-gameplay-prediction/\"\n",
    "    elif platform.system() == 'Darwin':\n",
    "        DIR = \"/Users/wooseokpark/github/kaggle/student-gameplay-prediction/\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # parser.add_argument(\"--target\", default=DIR + \"data/raw/input/train_labels.csv\", type=str, help=\"target csv\")\n",
    "    parser.add_argument(\"--target\", default=DIR + \"data/processed/concat/total_target_full_labeled.parquet\", type=str, help=\"target csv\")\n",
    "    # parser.add_argument(\"--train\", default=DIR + \"data/raw/input/train.parquet\", type=str, help=\"train parquet\")\n",
    "    parser.add_argument(\"--train\", default=DIR + \"data/processed/concat/total_train_fully_labeled.parquet\", type=str, help=\"train parquet\")\n",
    "    parser.add_argument(\"--model_path\", default=DIR + \"boosting/models/\", type=str, help=\"model path\")\n",
    "    parser.add_argument(\"--cv\", default=1, type=int, help=\"using cross-validation\")\n",
    "    # parser.add_argument(\"--nullcol\", default=DIR + \"boosting/processed/null_feat.npy\", type=str, help=\"null cols\")\n",
    "    parser.add_argument(\"--processed\", default=DIR + \"boosting/processed/\", type=str, help=\"processed path\")\n",
    "    parser.add_argument(\"--model\", default='xgb', type=str, help='which model')\n",
    "    parser.add_argument(\"--model_file\", default=DIR + \"boosting/processed/model.pkl\", type=str)\n",
    "    parser.add_argument(\"--result_file\", default=DIR + \"boosting/processed/result.pkl\", type=str)\n",
    "    parser.add_argument(\"--level_group\", default=\"0-4\", type=str)\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "\n",
    "targets = load_targets(args)\n",
    "df = pd.read_parquet(args.train)\n",
    "\n",
    "# remove outlier users\n",
    "# outliers = np.load(args.processed + 'outlier_users.npy')\n",
    "# df = df.set_index('session_id').drop(outliers).reset_index()\n",
    "\n",
    "args.level_group = '13-22'\n",
    "# save & load models and results\n",
    "# if args.level_group == '0-4':\n",
    "#     models = {}\n",
    "#     results = [[[], []] for _ in range(18)]\n",
    "# else:\n",
    "#     models = pickle.load(open(args.model_file, 'rb'))\n",
    "#     results = pickle.load(open(args.result_file, 'rb'))\n",
    "    \n",
    "\n",
    "list_q = {'0-4':[1,2,3], '5-12':[4,5,6,7,8,9,10,11,12,13], '13-22':[14,15,16,17,18]}\n",
    "# groups = ['0-4', '5-12', '13-22']\n",
    "\n",
    "# for grp in tqdm(groups):\n",
    "grp = args.level_group\n",
    "df_grp = df[df['level_group'] == grp]\n",
    "train, old_train = preprocessing(df_grp, grp)\n",
    "old_train = old_train[old_train['level_group'] == grp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_number_</th>\n",
       "      <th>word_that</th>\n",
       "      <th>word_this</th>\n",
       "      <th>word_it</th>\n",
       "      <th>word_you</th>\n",
       "      <th>word_find</th>\n",
       "      <th>word_found</th>\n",
       "      <th>word_Found</th>\n",
       "      <th>word_notebook</th>\n",
       "      <th>word_Wells</th>\n",
       "      <th>...</th>\n",
       "      <th>13-22_ET_quant75_</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>id_anonymous</th>\n",
       "      <th>recap_reading</th>\n",
       "      <th>reading_cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19100214260828124</th>\n",
       "      <td>724</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>28124</td>\n",
       "      <td>3.0</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100215310930160</th>\n",
       "      <td>501</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>30160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100216464688092</th>\n",
       "      <td>493</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2502.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>88092</td>\n",
       "      <td>2.0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100216534499230</th>\n",
       "      <td>411</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>99230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100217274021024</th>\n",
       "      <td>451</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>21024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100620341836400</th>\n",
       "      <td>523</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>36400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100622384891210</th>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>91210</td>\n",
       "      <td>4.0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100622514686336</th>\n",
       "      <td>493</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>86336</td>\n",
       "      <td>3.0</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100623301004070</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22110412365882880</th>\n",
       "      <td>487</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>82880</td>\n",
       "      <td>5.0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31314 rows × 2465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   session_number_  word_that  word_this  word_it  word_you  \\\n",
       "session_id                                                                    \n",
       "19100214260828124              724          5         11       36        44   \n",
       "19100215310930160              501          4         11       34        40   \n",
       "19100216464688092              493          4         12       38        42   \n",
       "19100216534499230              411          4         11       35        42   \n",
       "19100217274021024              451          5         11       34        44   \n",
       "...                            ...        ...        ...      ...       ...   \n",
       "22100620341836400              523          5          7       27        31   \n",
       "22100622384891210              400          5          7       31        37   \n",
       "22100622514686336              493          6          9       31        39   \n",
       "22100623301004070              400          4         10       33        41   \n",
       "22110412365882880              487          5          8       31        36   \n",
       "\n",
       "                   word_find  word_found  word_Found  word_notebook  \\\n",
       "session_id                                                            \n",
       "19100214260828124          8           5           0              0   \n",
       "19100215310930160          8           5           0              0   \n",
       "19100216464688092          8           5           0              0   \n",
       "19100216534499230          8           5           0              0   \n",
       "19100217274021024          8           5           0              0   \n",
       "...                      ...         ...         ...            ...   \n",
       "22100620341836400          9           5           0              0   \n",
       "22100622384891210          8           5           0              0   \n",
       "22100622514686336          8           5           0              0   \n",
       "22100623301004070          9           5           0              0   \n",
       "22110412365882880          8           5           0              0   \n",
       "\n",
       "                   word_Wells  ...  13-22_ET_quant75_  year  month  day  hour  \\\n",
       "session_id                     ...                                              \n",
       "19100214260828124           4  ...             1117.0    19     11    2    14   \n",
       "19100215310930160           4  ...             1516.0    19     11    2    15   \n",
       "19100216464688092           4  ...             2502.0    19     11    2    16   \n",
       "19100216534499230           4  ...             1233.0    19     11    2    16   \n",
       "19100217274021024           4  ...             1279.0    19     11    2    17   \n",
       "...                       ...  ...                ...   ...    ...  ...   ...   \n",
       "22100620341836400           4  ...             1896.0    22     11    6    20   \n",
       "22100622384891210           4  ...             1749.0    22     11    6    22   \n",
       "22100622514686336           4  ...             1168.0    22     11    6    22   \n",
       "22100623301004070           4  ...             1951.0    22     11    6    23   \n",
       "22110412365882880           4  ...             1684.0    22     12    4    12   \n",
       "\n",
       "                   minute  second  id_anonymous  recap_reading  reading_cnt  \n",
       "session_id                                                                   \n",
       "19100214260828124      26       8         28124            3.0          212  \n",
       "19100215310930160      31       9         30160            1.0          200  \n",
       "19100216464688092      46      46         88092            2.0          207  \n",
       "19100216534499230      53      44         99230            1.0          204  \n",
       "19100217274021024      27      40         21024            2.0          212  \n",
       "...                   ...     ...           ...            ...          ...  \n",
       "22100620341836400      34      18         36400            NaN          161  \n",
       "22100622384891210      38      48         91210            4.0          172  \n",
       "22100622514686336      51      46         86336            3.0          170  \n",
       "22100623301004070      30      10          4070            1.0          207  \n",
       "22110412365882880      36      58         82880            5.0          172  \n",
       "\n",
       "[31314 rows x 2465 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['session_number_', 'word_that', 'word_this', ..., 'id_anonymous',\n",
       "       'recap_reading', 'reading_cnt'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_found\n",
      "word_wells\n",
      "word_Oh\n",
      "word_flag\n",
      "elapsed_time_diff_min_\n",
      "tunic.kohlcenter.halloffame_ET_min_\n",
      "1_ET_min_\n",
      "2_ET_min_\n",
      "3_ET_min_\n",
      "4_ET_min_\n",
      "5-12_LEVEL_group_count\n",
      "13-22_LEVEL_group_count\n",
      "0-4_ET_min_\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_number_</th>\n",
       "      <th>word_that</th>\n",
       "      <th>word_this</th>\n",
       "      <th>word_it</th>\n",
       "      <th>word_you</th>\n",
       "      <th>word_find</th>\n",
       "      <th>word_Found</th>\n",
       "      <th>word_notebook</th>\n",
       "      <th>word_Wells</th>\n",
       "      <th>word_help</th>\n",
       "      <th>...</th>\n",
       "      <th>0-4_ET_quant75_</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>id_anonymous</th>\n",
       "      <th>recap_reading</th>\n",
       "      <th>reading_cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19100214260828124</th>\n",
       "      <td>525</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>784.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>28124</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100215310930160</th>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>30160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100216464688092</th>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3211.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>88092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100216534499230</th>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>99230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100217274021024</th>\n",
       "      <td>139</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>21024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100620341836400</th>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>36400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100622384891210</th>\n",
       "      <td>159</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>91210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100622514686336</th>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>86336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100623301004070</th>\n",
       "      <td>126</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22110412365882880</th>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>82880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31313 rows × 1103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   session_number_  word_that  word_this  word_it  word_you  \\\n",
       "session_id                                                                    \n",
       "19100214260828124              525          4          3       11        11   \n",
       "19100215310930160              132          4          3       11        11   \n",
       "19100216464688092              201          4          3       11        11   \n",
       "19100216534499230              135          4          3       13        13   \n",
       "19100217274021024              139          4          3       11        11   \n",
       "...                            ...        ...        ...      ...       ...   \n",
       "22100620341836400              138          4          2       12        11   \n",
       "22100622384891210              159          4          2       10        11   \n",
       "22100622514686336              175          3          3       11        10   \n",
       "22100623301004070              126          5          2       10         9   \n",
       "22110412365882880              157          3          3       11        10   \n",
       "\n",
       "                   word_find  word_Found  word_notebook  word_Wells  \\\n",
       "session_id                                                            \n",
       "19100214260828124          2           1              3           2   \n",
       "19100215310930160          2           1              3           2   \n",
       "19100216464688092          2           1              3           2   \n",
       "19100216534499230          2           1              3           2   \n",
       "19100217274021024          2           1              3           2   \n",
       "...                      ...         ...            ...         ...   \n",
       "22100620341836400          1           1              3           2   \n",
       "22100622384891210          2           1              3           2   \n",
       "22100622514686336          1           1              3           2   \n",
       "22100623301004070          1           1              3           2   \n",
       "22110412365882880          1           1              3           2   \n",
       "\n",
       "                   word_help  ...  0-4_ET_quant75_  year  month  day  hour  \\\n",
       "session_id                    ...                                            \n",
       "19100214260828124          2  ...            784.0    19     11    2    14   \n",
       "19100215310930160          2  ...           2315.0    19     11    2    15   \n",
       "19100216464688092          2  ...           3211.0    19     11    2    16   \n",
       "19100216534499230          2  ...           1748.0    19     11    2    16   \n",
       "19100217274021024          2  ...           1384.0    19     11    2    17   \n",
       "...                      ...  ...              ...   ...    ...  ...   ...   \n",
       "22100620341836400          2  ...           1970.0    22     11    6    20   \n",
       "22100622384891210          2  ...           1598.0    22     11    6    22   \n",
       "22100622514686336          2  ...           1302.0    22     11    6    22   \n",
       "22100623301004070          2  ...           2384.0    22     11    6    23   \n",
       "22110412365882880          2  ...           1952.0    22     12    4    12   \n",
       "\n",
       "                   minute  second  id_anonymous  recap_reading  reading_cnt  \n",
       "session_id                                                                   \n",
       "19100214260828124      26       8         28124            3.0         72.0  \n",
       "19100215310930160      31       9         30160            NaN         57.0  \n",
       "19100216464688092      46      46         88092            1.0         58.0  \n",
       "19100216534499230      53      44         99230            NaN         59.0  \n",
       "19100217274021024      27      40         21024            NaN         56.0  \n",
       "...                   ...     ...           ...            ...          ...  \n",
       "22100620341836400      34      18         36400            NaN         52.0  \n",
       "22100622384891210      38      48         91210            1.0         56.0  \n",
       "22100622514686336      51      46         86336            NaN         55.0  \n",
       "22100623301004070      30      10          4070            NaN         54.0  \n",
       "22110412365882880      36      58         82880            NaN         52.0  \n",
       "\n",
       "[31313 rows x 1103 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "null = train.isnull().sum().sort_values(ascending=False) / len(train)\n",
    "drop = list(null[null > 0.9].index)\n",
    "for col in [c for c in train.columns if c not in drop]:\n",
    "    if train[col].nunique() == 1:\n",
    "        print(col)\n",
    "        drop.append(col)\n",
    "FEATURES = [c for c in train.columns if c not in drop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(drop)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drop' is not defined"
     ]
    }
   ],
   "source": [
    "len(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_found\n",
      "word_wells\n",
      "word_Oh\n",
      "word_flag\n",
      "elapsed_time_diff_min_\n",
      "tunic.historicalsociety.entry.gramps.hub_ET_skew_\n",
      "tunic.historicalsociety.entry.gramps.hub_ET_kurtosis_\n",
      "tunic.kohlcenter.halloffame_ET_min_\n",
      "1_ET_min_\n",
      "2_ET_min_\n",
      "3_ET_min_\n",
      "4_ET_min_\n",
      "5-12_LEVEL_group_count\n",
      "13-22_LEVEL_group_count\n",
      "0-4_ET_min_\n"
     ]
    }
   ],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].nunique() == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        # 'booster': 'gbtree',\n",
    "        'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "models = {}\n",
    "# results = [[[], []] for _ in range(18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 15\n",
    "\n",
    "train_q = feature_quest(train, old_train, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_number_</th>\n",
       "      <th>word_that</th>\n",
       "      <th>word_this</th>\n",
       "      <th>word_it</th>\n",
       "      <th>word_you</th>\n",
       "      <th>word_find</th>\n",
       "      <th>word_found</th>\n",
       "      <th>word_Found</th>\n",
       "      <th>word_notebook</th>\n",
       "      <th>word_Wells</th>\n",
       "      <th>...</th>\n",
       "      <th>id_anonymous</th>\n",
       "      <th>recap_reading</th>\n",
       "      <th>reading_cnt</th>\n",
       "      <th>t_fqid_groupconvo_flag</th>\n",
       "      <th>t_text_fqid_tunic.flaghouse.entry.colorbook</th>\n",
       "      <th>l_text_fqid_tunic.flaghouse.entry.colorbook</th>\n",
       "      <th>t_tunic.historicalsociety.entry15</th>\n",
       "      <th>l_tunic.historicalsociety.entry15</th>\n",
       "      <th>t_tunic.library.frontdesk20</th>\n",
       "      <th>l_tunic.library.frontdesk20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19100214260828124</th>\n",
       "      <td>724</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>28124</td>\n",
       "      <td>3.0</td>\n",
       "      <td>212</td>\n",
       "      <td>18769.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27918.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13067.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100215310930160</th>\n",
       "      <td>501</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>30160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>24575.0</td>\n",
       "      <td>6570.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20557.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100216464688092</th>\n",
       "      <td>493</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>88092</td>\n",
       "      <td>2.0</td>\n",
       "      <td>207</td>\n",
       "      <td>44452.0</td>\n",
       "      <td>14567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40186.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17265.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100216534499230</th>\n",
       "      <td>411</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>99230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204</td>\n",
       "      <td>18468.0</td>\n",
       "      <td>2653.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12688.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10625.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100217274021024</th>\n",
       "      <td>451</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>21024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212</td>\n",
       "      <td>14816.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29967.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10309.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100620341836400</th>\n",
       "      <td>523</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>36400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>28252.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23305.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39695.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100622384891210</th>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>91210</td>\n",
       "      <td>4.0</td>\n",
       "      <td>172</td>\n",
       "      <td>19776.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16814.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15340.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100622514686336</th>\n",
       "      <td>493</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>86336</td>\n",
       "      <td>3.0</td>\n",
       "      <td>170</td>\n",
       "      <td>17685.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13147.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100623301004070</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207</td>\n",
       "      <td>24101.0</td>\n",
       "      <td>5069.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24651.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13416.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22110412365882880</th>\n",
       "      <td>487</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>82880</td>\n",
       "      <td>5.0</td>\n",
       "      <td>172</td>\n",
       "      <td>19842.0</td>\n",
       "      <td>4923.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16016.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17148.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31314 rows × 2472 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   session_number_  word_that  word_this  word_it  word_you  \\\n",
       "session_id                                                                    \n",
       "19100214260828124              724          5         11       36        44   \n",
       "19100215310930160              501          4         11       34        40   \n",
       "19100216464688092              493          4         12       38        42   \n",
       "19100216534499230              411          4         11       35        42   \n",
       "19100217274021024              451          5         11       34        44   \n",
       "...                            ...        ...        ...      ...       ...   \n",
       "22100620341836400              523          5          7       27        31   \n",
       "22100622384891210              400          5          7       31        37   \n",
       "22100622514686336              493          6          9       31        39   \n",
       "22100623301004070              400          4         10       33        41   \n",
       "22110412365882880              487          5          8       31        36   \n",
       "\n",
       "                   word_find  word_found  word_Found  word_notebook  \\\n",
       "session_id                                                            \n",
       "19100214260828124          8           5           0              0   \n",
       "19100215310930160          8           5           0              0   \n",
       "19100216464688092          8           5           0              0   \n",
       "19100216534499230          8           5           0              0   \n",
       "19100217274021024          8           5           0              0   \n",
       "...                      ...         ...         ...            ...   \n",
       "22100620341836400          9           5           0              0   \n",
       "22100622384891210          8           5           0              0   \n",
       "22100622514686336          8           5           0              0   \n",
       "22100623301004070          9           5           0              0   \n",
       "22110412365882880          8           5           0              0   \n",
       "\n",
       "                   word_Wells  ...  id_anonymous  recap_reading  reading_cnt  \\\n",
       "session_id                     ...                                             \n",
       "19100214260828124           4  ...         28124            3.0          212   \n",
       "19100215310930160           4  ...         30160            1.0          200   \n",
       "19100216464688092           4  ...         88092            2.0          207   \n",
       "19100216534499230           4  ...         99230            1.0          204   \n",
       "19100217274021024           4  ...         21024            2.0          212   \n",
       "...                       ...  ...           ...            ...          ...   \n",
       "22100620341836400           4  ...         36400            NaN          161   \n",
       "22100622384891210           4  ...         91210            4.0          172   \n",
       "22100622514686336           4  ...         86336            3.0          170   \n",
       "22100623301004070           4  ...          4070            1.0          207   \n",
       "22110412365882880           4  ...         82880            5.0          172   \n",
       "\n",
       "                   t_fqid_groupconvo_flag  \\\n",
       "session_id                                  \n",
       "19100214260828124                 18769.0   \n",
       "19100215310930160                 24575.0   \n",
       "19100216464688092                 44452.0   \n",
       "19100216534499230                 18468.0   \n",
       "19100217274021024                 14816.0   \n",
       "...                                   ...   \n",
       "22100620341836400                 28252.0   \n",
       "22100622384891210                 19776.0   \n",
       "22100622514686336                 17685.0   \n",
       "22100623301004070                 24101.0   \n",
       "22110412365882880                 19842.0   \n",
       "\n",
       "                   t_text_fqid_tunic.flaghouse.entry.colorbook  \\\n",
       "session_id                                                       \n",
       "19100214260828124                                       2623.0   \n",
       "19100215310930160                                       6570.0   \n",
       "19100216464688092                                      14567.0   \n",
       "19100216534499230                                       2653.0   \n",
       "19100217274021024                                       1850.0   \n",
       "...                                                        ...   \n",
       "22100620341836400                                        961.0   \n",
       "22100622384891210                                       1768.0   \n",
       "22100622514686336                                       1051.0   \n",
       "22100623301004070                                       5069.0   \n",
       "22110412365882880                                       4923.0   \n",
       "\n",
       "                   l_text_fqid_tunic.flaghouse.entry.colorbook  \\\n",
       "session_id                                                       \n",
       "19100214260828124                                          1.0   \n",
       "19100215310930160                                          1.0   \n",
       "19100216464688092                                          1.0   \n",
       "19100216534499230                                          1.0   \n",
       "19100217274021024                                          1.0   \n",
       "...                                                        ...   \n",
       "22100620341836400                                          1.0   \n",
       "22100622384891210                                          1.0   \n",
       "22100622514686336                                          1.0   \n",
       "22100623301004070                                          1.0   \n",
       "22110412365882880                                          1.0   \n",
       "\n",
       "                   t_tunic.historicalsociety.entry15  \\\n",
       "session_id                                             \n",
       "19100214260828124                            27918.0   \n",
       "19100215310930160                            20557.0   \n",
       "19100216464688092                            40186.0   \n",
       "19100216534499230                            12688.0   \n",
       "19100217274021024                            29967.0   \n",
       "...                                              ...   \n",
       "22100620341836400                            23305.0   \n",
       "22100622384891210                            16814.0   \n",
       "22100622514686336                             1435.0   \n",
       "22100623301004070                            24651.0   \n",
       "22110412365882880                            16016.0   \n",
       "\n",
       "                   l_tunic.historicalsociety.entry15  \\\n",
       "session_id                                             \n",
       "19100214260828124                               26.0   \n",
       "19100215310930160                               12.0   \n",
       "19100216464688092                               12.0   \n",
       "19100216534499230                                8.0   \n",
       "19100217274021024                               10.0   \n",
       "...                                              ...   \n",
       "22100620341836400                                9.0   \n",
       "22100622384891210                                7.0   \n",
       "22100622514686336                                2.0   \n",
       "22100623301004070                               10.0   \n",
       "22110412365882880                               11.0   \n",
       "\n",
       "                   t_tunic.library.frontdesk20  l_tunic.library.frontdesk20  \n",
       "session_id                                                                   \n",
       "19100214260828124                      13067.0                         12.0  \n",
       "19100215310930160                      15420.0                         16.0  \n",
       "19100216464688092                      17265.0                         14.0  \n",
       "19100216534499230                      10625.0                         10.0  \n",
       "19100217274021024                      10309.0                         12.0  \n",
       "...                                        ...                          ...  \n",
       "22100620341836400                      39695.0                         51.0  \n",
       "22100622384891210                      15340.0                          9.0  \n",
       "22100622514686336                      13147.0                         16.0  \n",
       "22100623301004070                      13416.0                         10.0  \n",
       "22110412365882880                      17148.0                         13.0  \n",
       "\n",
       "[31314 rows x 2472 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users = train_q.index.values\n",
    "train_y = targets.loc[targets.q==q].set_index('session').loc[train_users]\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "f1_list, precision_list, recall_list = [], [], []\n",
    "# print('Fold:', end= '')\n",
    "# for k, (train_idx, val_idx) in enumerate(gkf.split(train_q, groups = train_users)):\n",
    "k = 0\n",
    "print(k+1, end=' ')\n",
    "\n",
    "X_train = train_q#.iloc[train_idx]\n",
    "# X_val = train_q.iloc[val_idx]\n",
    "\n",
    "y_train = train_y['correct']\n",
    "# y_train = train_y.iloc[train_idx]['correct']\n",
    "# y_val = train_y.iloc[val_idx]['correct'].values\n",
    "\n",
    "# if args.model == 'xgb':\n",
    "model = XGBClassifier(\n",
    "    **xgb_params\n",
    ")\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# elif args.model == 'catboost':\n",
    "#     model = CatBoostClassifier(\n",
    "#     **cat_params\n",
    "# )\n",
    "#     model.fit(X_train, y_train, verbose=False,\n",
    "#                 cat_features = cate_cols)\n",
    "\n",
    "\n",
    "# SAVE MODEL\n",
    "# models[(k, q)] = model #fold, q\n",
    "\n",
    "# y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "# # scores\n",
    "# f1 = f1_score(y_val, y_pred > 0.5, average='macro')\n",
    "# precision = precision_score(y_val, y_pred > 0.5)\n",
    "# recall = recall_score(y_val, y_pred > 0.5)\n",
    "# f1_list.append(f1); precision_list.append(precision); recall_list.append(recall)\n",
    "\n",
    "#     # results[q - 1][0].append(y_val)\n",
    "#     # results[q - 1][1].append(y_pred)\n",
    "\n",
    "# print()\n",
    "# print(f'Question {q} - Scores after {k+1} fold: F1: {np.mean(f1_list):.5f} Precision: {np.mean(precision_list):.5f} Recall: {np.mean(recall_list):.5f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00050132, 0.        , 0.00064761, ..., 0.00059233, 0.00043256,\n",
       "       0.00091952], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "importance_df = pd.DataFrame()\n",
    "importance_df['feature'] = X_train.columns\n",
    "importance_df[\"importance\"] = model.feature_importances_\n",
    "\n",
    "cols = importance_df.loc[(importance_df.sort_values('importance', ascending=False)['importance'] != 0), 'feature'].values\n",
    "np.save('../data/features/g3_feature_posimp.npy', cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
